# Architecture Design: `wc` CLI Tool (Python)

---

## 1. Overview

A command-line tool that replicates the Unix `wc` command. It reads input from files or `stdin`, and outputs statistics like line count, word count, character count, and byte count.

---

## 2. Supported Flags

| Flag | Feature | Description |
|------|---------|-------------|
| `-l` | Line Count | Number of newline characters |
| `-w` | Word Count | Words delimited by whitespace |
| `-c` | Byte Count | Size in bytes |
| `-m` | Character Count | Number of characters (encoding-aware) |
| `-L` | Max Line Length | Length of the longest line |
| *(none)* | Default | Show lines, words, and bytes (like real `wc`) |

---

## 3. Input Methods

| Method | Example |
|--------|---------|
| Single file | `mywc file.txt` |
| Multiple files | `mywc file1.txt file2.txt` |
| Stdin (pipe) | `cat file.txt \| mywc` |
| Stdin (interactive) | `mywc` then type, end with `Ctrl+D` |

---

## 4. High-Level Architecture

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê     ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê     ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê     ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê     ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  CLI Parser  ‚îÇ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∂‚îÇ  Input       ‚îÇ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∂‚îÇ  Controller  ‚îÇ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∂‚îÇ  Processor   ‚îÇ‚îÄ‚îÄ‚îÄ‚îÄ‚ñ∂‚îÇ  Output      ‚îÇ
‚îÇ  (args/flags)‚îÇ     ‚îÇ  Reader      ‚îÇ     ‚îÇ (orchestrate)‚îÇ     ‚îÇ  (counting)  ‚îÇ     ‚îÇ  Formatter   ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò     ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò     ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò     ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò     ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

| Layer | Responsibility |
|-------|---------------|
| CLI Parser | Parse command-line arguments: flags + file paths |
| Input Reader | Open files or read from `stdin`, handle encoding & errors |
| Controller | Orchestrate iteration over files, collect `Result` objects |
| Processor | Core counting logic (lines, words, chars, bytes) via streaming |
| Output Formatter | Format results into aligned columns, print to `stdout` |

---

## 5. Module / Class Structure

```
project/
‚îú‚îÄ‚îÄ main.py                  # Entry point ‚Äî parse args, delegate to controller
‚îÇ
‚îú‚îÄ‚îÄ cli_parser.py
‚îÇ   ‚îú‚îÄ‚îÄ Parse flags (-l, -w, -c, -m, -L)
‚îÇ   ‚îú‚îÄ‚îÄ Extract file paths
‚îÇ   ‚îî‚îÄ‚îÄ Detect stdin mode
‚îÇ
‚îú‚îÄ‚îÄ input_reader.py
‚îÇ   ‚îú‚îÄ‚îÄ read_file(path) ‚Üí byte stream (chunked)
‚îÇ   ‚îú‚îÄ‚îÄ read_stdin() ‚Üí byte stream (chunked)
‚îÇ   ‚îî‚îÄ‚îÄ Handle errors (file not found, permissions, encoding)
‚îÇ
‚îú‚îÄ‚îÄ controller.py            # NEW: Orchestration layer
‚îÇ   ‚îú‚îÄ‚îÄ run(flags, file_paths) ‚Üí list[Result]
‚îÇ   ‚îú‚îÄ‚îÄ Iterates over files, invokes reader + processor per file
‚îÇ   ‚îî‚îÄ‚îÄ Collects and returns all Result objects for formatting
‚îÇ
‚îú‚îÄ‚îÄ processor.py             # Pure logic ‚Äî no I/O, no side effects
‚îÇ   ‚îú‚îÄ‚îÄ analyze(stream, flags) ‚Üí Result   # accepts a byte stream/generator
‚îÇ   ‚îú‚îÄ‚îÄ _count_lines(chunk, state) ‚Üí int
‚îÇ   ‚îú‚îÄ‚îÄ _count_words(chunk, state) ‚Üí int
‚îÇ   ‚îú‚îÄ‚îÄ _count_bytes(chunk) ‚Üí int
‚îÇ   ‚îú‚îÄ‚îÄ _count_chars(chunk) ‚Üí int
‚îÇ   ‚îî‚îÄ‚îÄ _max_line_length(chunk, state) ‚Üí int
‚îÇ
‚îú‚îÄ‚îÄ processor_state.py       # NEW: Inter-chunk state tracking
‚îÇ   ‚îî‚îÄ‚îÄ WcContext dataclass
‚îÇ       ‚îú‚îÄ‚îÄ prev_ended_mid_word: bool    # tracks word split across chunks
‚îÇ       ‚îú‚îÄ‚îÄ partial_line_buffer: str     # tracks line split across chunks
‚îÇ       ‚îî‚îÄ‚îÄ accumulated: Result          # running totals
‚îÇ
‚îú‚îÄ‚îÄ result.py                # Data model
‚îÇ   ‚îú‚îÄ‚îÄ file_name: str
‚îÇ   ‚îú‚îÄ‚îÄ lines: int
‚îÇ   ‚îú‚îÄ‚îÄ words: int
‚îÇ   ‚îú‚îÄ‚îÄ bytes: int
‚îÇ   ‚îú‚îÄ‚îÄ chars: int
‚îÇ   ‚îî‚îÄ‚îÄ max_line_length: int
‚îÇ
‚îú‚îÄ‚îÄ output_formatter.py
‚îÇ   ‚îú‚îÄ‚îÄ format_single(result, flags) ‚Üí str
‚îÇ   ‚îú‚îÄ‚îÄ format_multiple(results, flags) ‚Üí str   # includes totals row
‚îÇ   ‚îî‚îÄ‚îÄ Column alignment logic
‚îÇ
‚îî‚îÄ‚îÄ errors.py
    ‚îú‚îÄ‚îÄ FileNotFoundError
    ‚îú‚îÄ‚îÄ PermissionError
    ‚îî‚îÄ‚îÄ EncodingError
```

---

## 6. Data Flow

```
CLI Input:  mywc -l -w file1.txt file2.txt

Step 1 ‚Äî CLI Parser
   ‚îú‚îÄ‚îÄ flags = { lines: true, words: true }
   ‚îî‚îÄ‚îÄ files = ["file1.txt", "file2.txt"]

Step 2 ‚Äî Controller
   ‚îî‚îÄ‚îÄ Iterates over each file path, delegates to reader + processor

Step 3 ‚Äî Input Reader
   ‚îú‚îÄ‚îÄ file1.txt ‚Üí chunked byte stream
   ‚îî‚îÄ‚îÄ file2.txt ‚Üí chunked byte stream

Step 4 ‚Äî Processor  (per file, streaming)
   ‚îú‚îÄ‚îÄ file1 ‚Üí Result { lines: 2, words: 4 }
   ‚îî‚îÄ‚îÄ file2 ‚Üí Result { lines: 1, words: 2 }

Step 5 ‚Äî Output Formatter
   ‚îú‚îÄ‚îÄ "  2   4  file1.txt"
   ‚îú‚îÄ‚îÄ "  1   2  file2.txt"
   ‚îî‚îÄ‚îÄ "  3   6  total"
```

---

## 7. Key Design Decisions

| Decision | Rationale |
|----------|-----------|
| Read as bytes first | Needed for accurate `-c` byte count; decode to text for `-w`, `-m`, `-l` |
| Stream processing for large files | Don't load entire file into memory ‚Äî read in 8KB chunks |
| Processor accepts a stream, not full content | Unifies streaming and in-memory paths; resolves API contradiction |
| `WcContext` carries inter-chunk state | Handles word/line boundaries that span chunk edges |
| Processor is pure logic | No I/O, no side effects ‚Äî easy to unit test |
| Separate formatter | Output formatting is independent of counting logic |
| Explicit `controller.py` | Clear orchestration layer ‚Äî `main` stays thin |
| Error handling per file | One bad file shouldn't crash the whole run (like real `wc`) |
| Default behavior | No flags = show lines + words + bytes (matches real `wc`) |
| Encoding default: UTF-8 | Best match for modern systems; add `--encoding` flag in future |

---

## 8. Edge Cases to Handle

| Case | Behavior |
|------|----------|
| Empty file | All counts = 0 |
| File with no trailing newline | Last line still counts for words/chars, but not as a newline |
| Binary files | Count bytes (`-c`) only; attempt decode with `errors='replace'` for other flags; emit a warning |
| Very large files (GBs) | Chunk-based processing (8KB buffer), never fully loaded into memory |
| Unicode (emoji, CJK) | `-m` counts code points; `-c` counts raw bytes |
| File not found | Print error to `stderr`, continue with remaining files |
| No read permission | Print error to `stderr`, continue |
| Empty stdin | All counts = 0 |
| Mixed flags | e.g., `-lw` or `-l -w` both work |
| Word split across chunk boundary | Tracked via `WcContext.prev_ended_mid_word` |

---

## 9. Streaming Strategy (for Large Files)

```
Open file as byte stream (8KB chunks)
  ‚îÇ
  ‚îú‚îÄ‚îÄ Read chunk
  ‚îÇ     ‚îú‚îÄ‚îÄ Accumulate byte count (len of raw chunk)
  ‚îÇ     ‚îú‚îÄ‚îÄ Decode chunk to text (UTF-8, errors='replace')
  ‚îÇ     ‚îú‚îÄ‚îÄ Count newlines in chunk
  ‚îÇ     ‚îú‚îÄ‚îÄ Count words ‚Äî check WcContext.prev_ended_mid_word for boundary
  ‚îÇ     ‚îú‚îÄ‚îÄ Count characters (code points)
  ‚îÇ     ‚îî‚îÄ‚îÄ Update WcContext with new state
  ‚îÇ
  ‚îú‚îÄ‚îÄ Repeat until EOF
  ‚îÇ
  ‚îî‚îÄ‚îÄ Return accumulated Result from WcContext
```

> ‚ö†Ô∏è **Tricky part:** A word can be split across two chunks. `WcContext.prev_ended_mid_word` tracks whether the previous chunk ended mid-word so the next chunk correctly continues or starts a new word count.

---

## 10. Testing Strategy

| Test Type | What to Test |
|-----------|-------------|
| Unit tests | Each counting function independently with known inputs |
| Integration tests | Full pipeline: args ‚Üí read ‚Üí process ‚Üí output |
| Edge case tests | Empty files, Unicode, binary, huge files |
| Golden / comparison tests | Run real `wc` and `mywc` on the same files; byte-for-byte output match |
| Stdin tests | Pipe input and verify results |
| Chunk boundary tests | Craft inputs where words/lines straddle the 8KB chunk boundary |

---

## 11. Language-Specific Notes (Python üêç)

- Use `argparse` for CLI parsing
- Use `open(file, 'rb')` and read in chunks for byte-level access
- `sys.stdin.buffer` for binary stdin
- `chunk.decode('utf-8', errors='replace')` for safe text decoding
- `len(text.encode('utf-8'))` for byte count from text
- Use `@dataclass` for `Result` and `WcContext`

---

## 12. Future Extensibility

| Feature | Description |
|---------|-------------|
| Parallel processing | Process multiple files concurrently with `threading` or `asyncio` |
| Recursive mode (`-r`) | Count all files in a directory tree |
| Custom delimiters | Count "words" by custom separators |
| Output formats | JSON, CSV output for scripting |
| Config file | `.mywcrc` for default flags |
| Glob support | `mywc *.txt` |
| `--encoding` flag | Let users specify input encoding (default: UTF-8) |

---
